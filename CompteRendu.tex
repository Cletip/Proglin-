% Created 2021-10-06 mer. 15:40
% Intended LaTeX compiler: pdflatex
\documentclass[letter]{article}
                      \usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[a4paper,left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage[frenchb, ]{babel}
\usepackage{libertine}
\usepackage[pdftex]{graphicx}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}
\newcommand{\hsp}{\hspace{20pt}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\date{\today}
\title{Résolution de systèmes linéaires : Méthodes directes}
\begin{document}


%chargement de la page de garde
\input{/home/msi/Documents/Org/Latex/Setupfile/Pagedegarde/Pagedegarde1/pagedegarde1.org}


\setcounter{tocdepth}{3}
\tableofcontents

\newpage




\section{Rappel rapide des méthodes}
\label{sec:orgabada95}
\subsection{Méthode de Gauss}
\label{sec:org29f71f8}
Cette méthode permet de trouver une solution exacte au système \(Ax = b\) en un nombre fini d'étape.


Pour ce faire, cette méthode se fait en plusieurs étapes :

\begin{enumerate}
\item La triangularisation
On doit passer du système \(Ax=b\) au système \(A'x=b'\) où A' est une matrice triangulaire supérieure. L'algorithme utilisé est disponible dans le programme.
\item La résolution facile \texttt{nécessite aucun 0 sur la diagonale de A}
\end{enumerate}

\subsection{Méthode de Jacobi}
\label{sec:orgeefc8ee}

Cette méthode fait partie des méthodes itératives, où l'on cherche à se rapprocher, avec une suite d'itération définie, à une solution exacte.

Pour cette méthode, nous devons tout d'abord décomposer A sous la forme A = D -E -F

\begin{enumerate}
\item D est la matrice nul de taille A, sauf sur sa diagonale où D possède les coefficients de A.
\item -E est la matrice triangulaire inférieure de A
\item -F est la matrice triangulaire supérieur de A
\end{enumerate}



De plus, on pose \(M = D\) et \(N = E + F\)

On obtient donc le système : 

\[Ax = b \Longleftrightarrow Dx^{k+1} = (E + F)x^k + b \]

pour l'itération \(k+1\)

De plus, l'algorithme de Jacobi s'écrit avec une précision \(\epsilon\) : 




\section{Présentation des programmes commentés}
\label{sec:org03b3d8e}

\subsection{Présentation Général :}
\label{sec:orgf6900d0}

\subsubsection{Les différents fichiers utilisés}
\label{sec:org00ffa6a}
Pour effectuer ce travail, nous avons décidé de séparer notre programme en plusieurs fichiers : 

\begin{enumerate}
\item main.c, qui est notre fichier appelant les divers fonctions présentent dans
\item fonction.c, puis
\item fonction.h, permettant de définir les différentes structures et les headers des fonctions, et enfin
\item main.h, où les différentes bibliothèques sont déclarées
\item De plus, il y a un Makefile, qui nous permet de compiler et tester notre programme efficacement
\end{enumerate}







\subsubsection{Les structures ainsi que les fonctions usuelles}
\label{sec:org2308d22}

\begin{enumerate}
\item La structure de nos matrice
\label{sec:orgab84745}

Nous avons choisis de définir notre structure matrice de la sorte :

\begin{verbatim}

  typedef struct matrice
{
  int longueur;
  int largeur;
  long double **Mat;
} matrice;

\end{verbatim}

Mettre la longueur et la largeur de la matrice directement dans la structure permet à nos fonction de ne plus les avoir en paramètre. De plus, les matrices sont des doubles tableaux. On utilise donc un pointeur de pointeur pour permettre aux différentes fonctions utilisées de pouvoir accéder à la matrice.


\item Les fonctions usuelles
\label{sec:org39d919e}


\begin{enumerate}
\item \emph{creerMatrice}, qui prend un paramètre la largeur et la longueur, et qui renvoie un pointeur de matrice. Cette fonction fait principalement la création et l'initialisation d'un tableau 2D avec des 0.
\begin{verbatim}

matrice *creerMatrice(int largeur, int longueur)
{
  /* création d'un pointeur sur une structure matrice (avec l'espace
     alloué de la structure matrice)  */
  matrice *fini = (matrice *)malloc(sizeof(matrice));

  /* attribution de la longueur et de la largeur */
  fini->longueur = longueur;
  fini->largeur = largeur;

  /* Création du double tableau, la matrice même (initialisé à 0)  */
  fini->Mat = (long double **)malloc(fini->longueur * sizeof(long double *));
  /* parcourt de la matrice avec la double boucle for */
  for (int i = 0; i < fini->longueur; i++)
    {
      fini->Mat[i] = (long double *)malloc(fini->largeur * sizeof(long double));
      for (int j = 0; j < fini->largeur; j++)
	{
	  fini->Mat[i][j] = 0;
	}
    }

  /* renvoie de la fini */
  return fini;
}     

\end{verbatim}

\item \emph{destroyMatrice}, qui permet de supprimer et de vider la mémoire d'une matrice.
\begin{verbatim}
void destroyMatrice(matrice *mat)
{
  for (int i = 0; i < mat->longueur; i++)
  {
    free(mat->Mat[i]);
  }
  free(mat->Mat);
  mat->longueur = 0;
  mat->largeur = 0;
  free(mat);
}
\end{verbatim}

\item \emph{afficheMatrice}, qui permet tout simplement d'afficher une matrice.

\item \emph{remplisAleaBcpZero}, qui permet de remplir une matrice avec environ 70\% de 0.

\item \emph{remplisAlea}, permettant de remplir une matrice avec des nombres aléatoire (etre -100 et 100)

\item \emph{remplisAleaInt}, déclinaison de remplisAlea avec des entier

\item \emph{additionMatrice}, qui, comme son nom l'indique, d'additionner 2 matrices
\begin{verbatim}
matrice *additionMatrice(matrice mat1, matrice mat2)
{
  // initialisation des variables
  matrice *fini;
  long double res;

  // initialisation de la matrice de retour

  // création de la matrice fini avec la taille de la taille max entre
  // 2 matrices
  fini = creerMatrice(
      (mat1.largeur > mat2.largeur) ? mat1.largeur : mat2.largeur,
      (mat1.longueur > mat2.longueur) ? mat1.longueur : mat2.longueur);

  // mise du resultat dans la matrice de retour
  for (int i = 0; i < fini->longueur; i++)
  {
    for (int j = 0; j < fini->largeur; j++)
    {
      res = 0;
      if ((mat1.longueur > i) && (mat1.largeur > j))
      {
	res += mat1.Mat[i][j];
      }
      if ((mat2.longueur > i) && (mat2.largeur > j))
      {
	res += mat2.Mat[i][j];
      }
      fini->Mat[i][j] = res;
    }
  }

  // retour de la matrice de resultat
  return fini;
}
\end{verbatim}

\item \emph{soustractino}, qui permet de les soustraire

\item \emph{multiplicationMatrice}, qui les multiplie
\begin{verbatim}
matrice *multiplicationMatrice(matrice mat1, matrice mat2)
{
  // verification des conditions
  if (mat1.largeur != mat2.longueur)
  {
    printf("On ne peu pas multiplier ces deux matrices ensemble.\n");
    return NULL;
  }

  // initialisation des variables
  matrice *Xfini = creerMatrice(mat2.largeur, mat1.longueur);
  long double lambda;
  /* afficheMatrice(mat1); */
  // calcule de chaque case une par une
  for (int i = 0; i < mat1.longueur; i++)
  {
    for (int j = 0; j < mat2.largeur; j++)
    {
      lambda = 0;
      for (int h = 0; h < mat1.largeur; h++)
      {
	lambda += (mat1.Mat[i][h] * mat2.Mat[h][j]);
      }
      Xfini->Mat[i][j] = lambda;
    }
  }

  return Xfini;
}
\end{verbatim}
\end{enumerate}
\end{enumerate}






\subsection{Gauss}
\label{sec:orgcec4756}

Pour cette méthode, nous procédons en deux grandes étapes :

\subsubsection{Échelonnage de la matrice A}
\label{sec:org6a16cd4}

Pour échelonner la matrice, TODO

\subsubsection{Application de la méthode}
\label{sec:org228b930}


\begin{enumerate}
\item Gestion des 0 sur la diagonale
\label{sec:orgd79be4c}

Tout d'abord, cette méthode requiert des nombres non nul sur la diagonale. Il faut donc tester, en échangeant certaines lignes, si il est possible d'obtenir une matrice avec aucun 0 sur les diagonales

\begin{verbatim}

int okayDiag = 0;


/* on compte le nombre de 0 sur la diagonale */
for (int i = 0; i < n; i++)
{
  if (res->Mat[i][i] == 0)
  {
    okayDiag++;
  }
}
while (okayDiag)
{
  int change = 0;
  for (int i = 0; i < n; i++)
  {
    if (res->Mat[i][i] == 0)
    {
      for (int j = 0; j < n; j++)
      {
	if (j < i)
	{
	  if (res->Mat[i][j] != 0 && res->Mat[j][i] != 0)
	  {
	    swapLine(res, i, j);
	    okayDiag--;
	    change++;
	    break;
	  }
	}
	else if (j > i)
	{
	  if (res->Mat[j][i] != 0)
	  {
	    if (res->Mat[i][j] != 0)
	    {
	      okayDiag--;
	    }
	    swapLine(res, i, j);
	    change++;
	    break;
	  }
	}
      }
    }
  }
  if (change == 0)
  {
    okayDiag = 0;
    for (int i = 0; i < n; i++)
    {
      if (res->Mat[i][i] == 0)
      {
	okayDiag++;
      }
    }
    if (okayDiag)
    {
      printf("La matrice ne peut avoir de diagonale sans zéros...\n");
      return res;
    }
  }
}

\end{verbatim}

\item Application de la méthode
\label{sec:org5189135}
Puis, on peut appliquer la méthode de Gauss sur la matrice augmentée AB

\begin{verbatim}

for (int i = 0; i < n; i++)
{
  for (int j = 0; j < i; j++)
  {
    lambda = -(A->Mat[i][j]);
    for (int k = 0; k < n; k++)
    {
      A->Mat[i][k] = lambda * A->Mat[j][k] + A->Mat[i][k];
    }
    res->Mat[i][0] = lambda * res->Mat[j][0] + res->Mat[i][0];
  }
  lambda = A->Mat[i][i];
  for (int k = 0; k < n; k++)
  {
    A->Mat[i][k] = A->Mat[i][k] / lambda;
  }
  res->Mat[i][0] = res->Mat[i][0] / lambda;
}




\end{verbatim}

\item Application de calcul simple
\label{sec:org6af641c}
Enfin, on peut appliquer le calcul simple sur matrice augmenté obtenue pour obtenir le résultat dans X

\begin{verbatim}

for (int i = n - 2; i > -1; i--)
  {
    lambda = 0;
    for (int j = i + 1; j < n; j++)
      {
	lambda -= (A->Mat[i][j] * res->Mat[j][0]);
      }
    res->Mat[i][0] += lambda;
  }

\end{verbatim}


Gauss : échelonne une matrice

Résolution gauss = matrice A augmenté
\end{enumerate}



\subsection{Jacobi}
\label{sec:org65f9d38}

\subsubsection{Gestion des matrices non diagonales dominantes}
\label{sec:org592da12}


Tout d'abord, pour utiliser la méthode de Jacobi, il faut que les matrices soient de la bonne taille. On vérifie donc que la matrice A est carré, que la longueur de A est égal à celle de B, ainsi que la largeur de B qui doit être égal à un. Ces conditions sont testés avec ce code :
\begin{verbatim}

/* gestion des cas d'erreur pouvant faire echouer la methode jacobi*/
if ((A->largeur != A->longueur) || (A->longueur != B->longueur) ||
    (B->largeur != 1))
{
  printf(
      "Les matrice ne sont pas de la taille nécessaire a leurs résolution.");
  return B;
}
 else


\end{verbatim}



Puis, il faut aussi que les matrices soient strictement diagonales dominantes.
Pour ce faire, nous pouvons mettre au début de la fonction "Jacobi", une double boucle for qui test si les diagonales sont bien dominantes :

\begin{verbatim}

  else
{
  for (int i = 0; i < A->longueur; i++)
  {
    int verifieur = 0;
    for (int j = 0; j < A->longueur; j++)
    {
      if (j != i)
      {
	verifieur += fabsl(A->Mat[i][j]);
      }
    }
    if (verifieur > A->Mat[i][i])
    {
      printf("La matrice n'est pas à diagonale dominante et ne vas donc pas "
	     "converger...\n");
      return B;
    }
  }
}


\end{verbatim}


Sinon, le reste du code est exécuté normalement.








\subsubsection{Méthode général}
\label{sec:orgb0f9ede}

\begin{enumerate}
\item Initialisation des différentes matrices nécessaires
\label{sec:org4a9afa7}

Suites à la création des matrices x, D, E, F (et N) à l'aide des fonction usuelles, il faut les initialiser avec les bonnes valeurs. On a choisit de faire un parcours de la matrice A, et lorsque les conditions sont réunies, nous entrons la valeur de A en fonction de la matrice.

\begin{verbatim}
  /* initialisation de D E et F (et N)*/
for (int i = 0; i < A->longueur; i++)
{
  for (int j = 0; j < A->largeur; j++)
  {
    if (i == j)
    {
      D->Mat[i][j] = A->Mat[i][j];
      E->Mat[i][j] = 0;
      F->Mat[i][j] = 0;
    }
    else if (i < j)
    {
      D->Mat[i][j] = 0;
      E->Mat[i][j] = -(A->Mat[i][j]);
      F->Mat[i][j] = 0;
    }
    else
    {
      D->Mat[i][j] = 0;
      E->Mat[i][j] = 0;
      F->Mat[i][j] = -(A->Mat[i][j]);
    }
    N->Mat[i][j] = E->Mat[i][j] + F->Mat[i][j];
  }
}


\end{verbatim}



\item Inversion de la matrice D
\label{sec:org7650b42}

Puis, on initialise la marge d'erreur. Nous inversons également D (avec la fonction \emph{InversematriceD}), car il faut utiliser \(D^{-1}\)


\begin{verbatim}

void InversematriceD(int taille, matrice *D)
{
  for (int i = 0; i < D->longueur; i++)
    {
      for (int j = 0; j < D->largeur; j++)
	{
	  if ((i == j) && (D->Mat[i][j] != 0))
	    {
	      D->Mat[i][j] = 1 / D->Mat[i][j];
	    }
	}
    }
}


float erreur = Eps + 1;
InversematriceD(D->longueur, D);


\end{verbatim}




\item Méthode de Jacobi appliquée
\label{sec:org0ca3fcd}

Enfin, nous programmons la méthode de Jacobi grâce aux fonctions "multiplicationMatrice, additionMatrice".
La boucle utiliser est un tant que, car nous ne savons pas quand la marge d'erreur sera respecté pour sortir de la boucle while.
La variable \emph{erreur} doit également être mise à jour à chaque passage dans la boucle, en utilisant la fonction \emph{Norme}.



\begin{verbatim}


float Norme(matrice *colonne)
{
  float norme = 0;
  for (int i = 0; i < colonne->longueur; ++i)
    {
      norme = norme + pow(colonne->Mat[i][0], 2);
    }
  return sqrt(norme);
}

while (erreur > Eps)
  {
    // nouvelle valeur de x selon la formule
    x = multiplicationMatrice(*D, *additionMatrice(*(multiplicationMatrice(*N, *x)), *B));
    // nouvelle valeur d'erreur selon la formule
    erreur = Norme(soustractino(*multiplicationMatrice(*A, *x), *B));

  }
return x;
}

\end{verbatim}
\end{enumerate}

\subsection{Programme final}
\label{sec:org917d540}

Les différentes fonctions sont appelées au fur et à mesure du main.c, en laissant le choix à l'utilisateur des matrices qu'il veut testes, ainsi que la méthode à utiliser pour la résolution. Les différents choix sont regroupés dans un switch.



\section{Présentation des matrices test au dos de la feuille}
\label{sec:orgdb846fc}

Nous ne mettrons le code des matrices test, mais vous pouvez le retrouver \href{matricetest.c}{ici}.


De plus, la plupart des matrices test sont compatibles uniquement avec la méthode de résolution de Gauss. En effet, seule les matrices Km\textsubscript{carré}, Bord ainsi que Lehmer seront diagonales dominantes.

Pour tester les différentes matrices proposées, il suffit de donner à A une taille \(n^n\), puis de la remplir grâce au programme de la matrice voulue. Le temps d'exécution de la résolution sera ainsi donné, avec la solution X. De plus, si la méthode choisie est la résolution par Jacobi, le nombre d'itération sera également affiché.








\section{Commentaires des jeux d'essais à partir de données relatives}
\label{sec:orgd092751}


Les jeux d'essais de données relatives proposés sont uniquement les cas où la matrice A est diagonale dominantes. Car, pour faire une comparaison, il faut obligatoirement pouvoir utiliser la méthode de Jacobi (nous avons quand même fait un test avec la matrice ding-dong et la méthode de Gauss).
Pour effectuer ces différents tests, nous avons choisi de faire un nouveau cas au switch, où l'on pourrait choisir :

\begin{enumerate}
\item La matrice A voulu
\item La matrice B voulu également
\item Le nombre de matrice à tester
\item La taille des matrices résoudre
\end{enumerate}





De plus, l'affichage dans le terminal indique :
\begin{enumerate}
\item Le temps nécessaire pour les 2 méthodes
\item La stabilité
\item La fonction d'erreur
\item La vitesse de convergence (le nombre d'itération de Jacobi)
\end{enumerate}



Par exemple, ici, avec :
\begin{itemize}
\item 1000 matrices carrées
\item de taille 100
\item A remplie aléatoirement avec des diagonales dominantes
\item B remplie aléatoirement avec des nombre entre -100 et 100

Nous avons les résultats suivants :
\end{itemize}


\begin{center}
\includegraphics[width=.9\linewidth]{resultattestjacogauss.png}
\end{center}


Vous pouvez également réaliser vos propres test en faisant tapant "p" dés le début du programme !

Grâce à ce test, nous pouvons en déduire plusieurs choses :


\subsection{Précision (pourcentage d'écart)}
\label{sec:orgb099977}
La précision de Jacobi est dû uniquement au \(\epsilon\) choisi. En effet, Jacobi s'arrête seulement lorsque la solution est proche de la solution exacte avec une marge de plus ou moins \(\epsilon\) (si la matrice A est bien diagonale dominante).
Pour Gauss, les résultats sont principalement exactes. En effet, Gauss permet de donner une précision avec une stabilité nul pour la plupart des cas.
Cependant, on peut citer la matrice remplie avec la méthode ding-dong, qui donne des résultats avec une précision peu fiable, même si la taille de la matrice est petite (par exemple 25). 


\subsection{Calcul de fonction d'erreurs}
\label{sec:org5d25491}

Pour la fonction d'erreur, il faut calculer la norme de \(AX - B\). Nous l'avons donc ajouté dans notre programme (tous n'est pas détaillé, mais se sont les 3 lignes principales):

\begin{verbatim}

X = multiplicationMatrice(*A, *X);
temporaire = soustractino(*X, *B);
ErreurJaco += Norme(temporaire);

\end{verbatim}

\subsection{Vitesse de convergence}
\label{sec:org1d0e6be}

Pour la vitesse de convergence, seul Jacobi sera traitée. En effet, Jacobi doit effectuer un nombre d'itération qui n'est pas défini avant le début du programme. Sa vitesse est donc affichée dans le terminal à la fin du programme.


\subsection{Complexité pratique}
\label{sec:orgddc74f6}

Dans notre algorithme, la méthode de Jacobi est d'une complexité de l'ordre de \(O(n^2)\), contrairement à Gauss qui nous donne une complexité de l'ordre de \(O(n^3)\).




\section{Conclusion sur les méthodes}
\label{sec:orgadc0b99}

\subsection{Comparaison}
\label{sec:org7a65f10}
Comme on peut le voir sur les différents jeux d'essais, Jacobi est plus efficace que Gauss, car sa complixité est \(3n^2+2n\) par itération, et donc d'ordre \(O(n^2)\), tandis que Gauss a une complixité égale à \(2\frac{n^3}{3}\) (\(\frac{n^2}{2}\) pour la division, et \(\frac{n^3}{3}\) pour la multiplication).
Gauss a donc une complexité d'ordre \(O(n^3)\).
Malgré tout, il existe des cas où la méthode de Jacobi prendra plus de temps : Il suffit de donner un \(\epsilon\) trés petit, et donc d'augmenter la précision du résultat voulu, pour entraîner un nombre d'itération trop conséquent pour effectuer un temps de calcul inférieur à celui de Gauss.


Les méthodes de Jacobi et de Gauss n'ont pas la même utilité : en effet, Jacobi est (en général) plus rapide que Gauss, mais donne une solution approchée en fonction du \(\epsilon\) choisi.


\subsection{Cadre d'utilisation}
\label{sec:orge281022}

Nous pouvons donc distinguer deux cas :

\begin{enumerate}
\item Nous voulons avoir une solution rapidement, mais la précision est négligeable à \(\epsilon\) près. Nous pouvons donc utiliser la méthode de Jacobi, qui s'effectuera plus rapidement que la méthode de Gauss.
\item Nous voulons une solution exacte et sans approximation : La méthode de Gauss s'impose d'elle-même. En revanche, le temps pour résoudre le système sera plus long que la méthode de Jacobi, mais la solution qui sera donnée sera exacte, et non une approximation à \(\epsilon\) près. Mais Gauss ne peut pas toujours être utilisé pour une précision de 100\%, comme avec la matrice ding-dong.
\end{enumerate}
\end{document}